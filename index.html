<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="Curriculum Vitae" />
        <meta name="author" content="Chonghan Lee" />
        <title>CV - Chonghan Lee</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
        <!-- Iconify - open source vector icons-->
        <script src="https://code.iconify.design/2/2.1.2/iconify.min.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top"
                ><span class="d-block d-lg-none">Chonghan Lee</span><span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile.jpeg" alt="..." /></span></a
            ><button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li> -->
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publication">Publication</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Experience</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#projects">Projects</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">Chonghan <span class="text-primary">Lee</span></h1>
                    <div class="subheading mb-5"><a href="mailto:cvl5361@psu.edu" style="text-decoration:none">  cvl5361 at psu.edu</a></div>
                    <p class="lead mb-5">I am a Ph.D. candidate at the Pennsylvania State University, advised by <a href="https://sites.psu.edu/vijaykrishnannarayanan/">Prof. Vijaykrishnan Narayanan</a>. I design optimization/compression algorithms for Deep Learning models and write code to build compute and memory-efficient Artificial Intelligent systems. My research interests include resource-constrained neural networks and HW/SW Co-design of deep learning for edge devices and In-Memory processing architectures.</p>
                    <div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/chonghan-lee-630571144/"><i class="fab fa-linkedin-in"></i></a><a class="social-icon" href="https://github.com/chleeee"><i class="fab fa-github"></i></a><a class="social-icon" href="https://scholar.google.com/citations?user=W702IvwAAAAJ"><i class="fab fa-google"></i></a>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Publication-->
            <section class="resume-section" id="publication">
                <div class="resume-section-content">
                    <h2 class="mb-5">Selected Publications / Preprints</h2>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-book"></i></span><a href="https://aspdac.gabia.io/accepted_papers/index.html" target="_blank"> <i>PRIMATE: Processing in Memory Acceleration for Dynamic Token-pruning Transformers</i></a><br>
                            Yue Pan, Minxuan Zhou, <b>Chonghan Lee</b>, Zheyu Li, Rishika Kushwah, Vijaykrishnan Narayanan, and Tajana Rosing<br>
                            In Proceedings of the 29th Asia and South Pacific Design Automation Conference (ASP-DAC). 2024.
                            <!-- <br><a href="bib/2010master.bib" target="_blank">[bibtex]</a> <a href="bib/2010master.bib" target="_blank">[code]</a> -->
                            <br>
                        </li>
                        <br>
                        <li>
                            <span class="fa-li"><i class="fas fa-book"></i></span><a href="https://ieeexplore.ieee.org/abstract/document/10222298" target="_blank"> <i>Multi-Exit Vision Transformer with Custom Fine-Tuning for Fine-Grained Image Recognition</i></a><br>
                            Tianyi Shen, <b>Chonghan Lee</b>, and Vijaykrishnan Narayanan<br>
                            In 2023 IEEE International Conference on Image Processing (ICIP). 2023.
                            <br><a href="bib/icip2023.bib" target="_blank">[bibtex]</a> <!--a href="bib/date2023.bib" target="_blank">[code]</a>-->
                            <br>
                        </li>
                        <br>
                        <li>
                            <span class="fa-li"><i class="fas fa-book"></i></span><a href="https://ieeexplore.ieee.org/document/10137239" target="_blank"> <i>Token Adaptive Vision Transformer with Efficient Deployment for Fine-Grained Image Recognition</i></a><br>
                            <b>Chonghan Lee</b>, Rita Brugarolas Brufau, Ke Ding, and Vijaykrishnan Narayanan<br>
                            In 2023 Design, Automation & Test in Europe Conference & Exhibition (DATE). 2023.
                            <br><a href="bib/date2023.bib" target="_blank">[bibtex]</a> <a href="https://github.com/imj2185/TAVT" target="_blank">[code]</a>
                            <br>
                        </li>
                        <br>
                        <li>
                            <span class="fa-li"><i class="fas fa-book"></i></span><a href="https://aclanthology.org/2022.coling-1.404/" target="_blank"> <i>Token and Head Adaptive Transformers for Efficient Natural Language Processing</i></a><br>
                            <b>Chonghan Lee</b>, Faysal Khan Md Fahim, Rita Brugarolas Brufau, Ke Ding, and Vijaykrishnan Narayanan<br>
                            In Proceedings of the 29th International Conference on Computational Linguistics (COLING). 2022.
                            <br><a href="bib/coling2022.bib" target="_blank">[bibtex]</a> <a href="https://github.com/imj2185/THAT_glue" target="_blank">[code]</a>
                            <br>
                        </li>
                        <br>
                        <li>
                            <span class="fa-li"><i class="fas fa-archive"></i></span><a href="https://arxiv.org/abs/2107.07089" target="_blank"> <i>Star: Sparse transformer-based action recognition</i></a><br>
                            Feng Shi, <b>Chonghan Lee</b>, Liang Qiu, Yizhou Zhao, Tianyi Shen, Shivran Muralidhar, Tian Han, Song-Chun Zhu, and Vijaykrishnan Narayanan<br>
                            arXiv preprint arXiv:2107.07089. (2021).
                            <br><a href="bib/arxiv2021.bib" target="_blank">[bibtex]</a> <a href="https://github.com/imj2185/STAR" target="_blank">[code]</a>
                            <br>
                        </li>
                        <br>
                        <li>
                            <span class="fa-li"><i class="fas fa-archive"></i></span><a href="https://arxiv.org/abs/2107.07116" target="_blank"> <i>Transformer-based Machine Learning for Fast SAT Solvers and Logic Synthesis</i></a><br>
                            Feng Shi, <b>Chonghan Lee</b>, Mohammad Khairul Bashar, Nikhil Shukla, Song-Chun Zhu, and Vijaykrishnan Narayanan<br>
                            arXiv preprint arXiv:2107.07116. (2021).
                            <br><a href="bib/arxiv2_2021.bib" target="_blank">[bibtex]</a> <!--a href="bib/date2023.bib" target="_blank">[code]</a>-->
                            <br>
                        </li>
                        <br>
                        <li>
                            <span class="fa-li"><i class="fas fa-book"></i></span><a href="https://dl.acm.org/doi/abs/10.1145/3373625.3417028" target="_blank"> <i>AIGuide: An Augmented Reality Hand Guidance Application for People with Visual Impairments</i></a><br>
                            Nelson Daniel Troncoso, Sooyeon Lee, <b>Chonghan Lee</b>, Mary Beth Rosson, John M. Carroll, and Vijaykrishnan Narayanan<br>
                            In The 22nd International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS). (2020).
                            <br><a href="bib/assets2020.bib" target="_blank">[bibtex]</a> <!--a href="bib/date2023.bib" target="_blank">[code]</a>-->
                            <br>
                        </li>
                        <br>
                        
                        
                    </ul>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Experience-->
            <section class="resume-section" id="experience">
                <div class="resume-section-content">
                    <h2 class="mb-5">Experience</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Machine Learning Engineer Intern</h3>
                            <div class="subheading mb-3">Intel, Santa Clara, CA</div>
                            <p>· Developed a novel Neural Architecture Search pipeline for Transformer models with weight sharing techniques to enhance model performance, automate efficient model search, and improve inference efficiency<br>
                                · Achieved a 7× speedup in the neural architecture search pipeline by implementing distributed evolutionary search on multiple HPC nodes using Ray<br>
                                · Integrated dynamic and static quantization into the neural architecture search pipeline to optimize model performance<br>
                                · Explored and tested hyper-parameter optimization tools, including Optuna and Sigopt, with various Transformer models including BERT, MobileBERT, DistillBERT, and RoBERTa<br>
                            </p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">June 2021 - December 2021</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Research Assistant</h3>
                            <div class="subheading mb-3">Pennsylvania State University, University Park, PA</div>
                            <p>
                                · Focused on designing resource constrained efficient neural networks, with a particular focus on Transformer models.<br>
                                · Proposed a token adaptive Vision Transformer, which dynamically and progressively drops out image patches based on attention probabilities, thereby significantly enhancing compute and memory efficiency. The model was successfully deployed and tested on edge devices<br>
                                · Proposed an In-memory HW-SW co-design acceleration framework that synergies Process In-Memory and Dynamic Token Pruning Transformer<br>
                                · Proposed a multi-exit Vision Transformer architecture, featuring an integrated uncertainty score predictor module, enabling dynamic early exits based on the inherent difficulty level of input images<br>
                                · Explored Transformer-based human action recognition model with a sparse self-attention module that efficiently performs sparse matrix multiplications to capture spatial correlations between human skeleton joints<br>
                            </p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2018 - Present</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Undergraduate Research Assistant</h3>
                            <div class="subheading mb-3">Pennsylvania State University, University Park, PA</div>
                            <p>
                                · Extracted Twitter data pertaining to specific enterprises and developed a co-occurrence network analysis model to discover influential terms within this Twitter data, potentially impact enterprise outcomes. Experiment results are reported in a journal paper.<br>
                                · Developed a website that leverages real-time social media data and population health statistics to create an interactive map interface using MapBox, effectively visualizing crucial health-related information.<br>
                            </p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">April 2017 - May 2018</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Education-->
            <section class="resume-section" id="education">
                <div class="resume-section-content">
                    <h2 class="mb-5">Education</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0"><a href="https://www.eecs.psu.edu/">Pennsylvania State University</a></h3>
                            <div class="subheading mb-3">Doctor of Philosophy in Computer Science and Engineering</div>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2018 - May 2024 expected</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0"><a href="https://www.eecs.psu.edu/">Pennsylvania State University</a></h3>
                            <div class="subheading mb-3">Bachelor of Science in Computer Science and Engineering</div>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2012 - May 2018</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Projects-->
            <section class="resume-section" id="projects">
                <div class="resume-section-content">
                    <h2 class="mb-5">Projects</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0"><a href="https://dl.acm.org/doi/10.1145/3373625.3417028">AIGuide</a></h3>
                            <div class="subheading mb-3">Awareded in <a href="https://nittanyai.psu.edu/alliance-programs/nittany-ai-challenge/results/2020-results/">2020 Nittany AI Challenge</a></div>
                            Developed a self-contained offline smartphone application that leverages augmented reality and machine learning technology to help users locate and pick up objects around them.<br>
                            <div>AIGuide Demo Video</div>
                            <p>
                                <iframe src="https://iframe.videodelivery.net/eyJraWQiOiI3YjgzNTg3NDZlNWJmNDM0MjY5YzEwZTYwMDg0ZjViYiIsImFsZyI6IlJTMjU2In0.eyJzdWIiOiJjMDAwZGJlY2Y5ZWVjYmI3NjQyY2NhOTExMmNmMGU3ZCIsImtpZCI6IjdiODM1ODc0NmU1YmY0MzQyNjljMTBlNjAwODRmNWJiIiwiZXhwIjoxNjk3MDU5NjgwfQ.AOnfVjP98oP5yoGiDGpf5qUHVda_NE5_aPxkTMezNcy0CiSaRFajpHhfZdpYS6w8y8gCP776d6qZ2mYKwu85OQOxEb6gfrn8v7Cf1I_XPfhB9CCtwjmJkOUMZRaq_BaIvq6FpE6Qr2tg0dlvVVt4DhS-51zSM67liC_D1uT0UYEkgn-X_wJNi8L8Sl7diNf2UFHStqpbYhM_1s_yEuImrvz93kFnjBcgbAqOvo11LyCXezdS9LD1o9vuIwIe18GrNeIBnXxuuEY_ZsAmdWREFiP_A_-YCWPy0Zfk8qXsLYwlpStQjXRlP7-OcTfrdS5Zy-pXtn8tt54F2x3eHbyXJg?poster=https%3A%2F%2Fvideodelivery.net%2FeyJraWQiOiI3YjgzNTg3NDZlNWJmNDM0MjY5YzEwZTYwMDg0ZjViYiIsImFsZyI6IlJTMjU2In0.eyJzdWIiOiJjMDAwZGJlY2Y5ZWVjYmI3NjQyY2NhOTExMmNmMGU3ZCIsImtpZCI6IjdiODM1ODc0NmU1YmY0MzQyNjljMTBlNjAwODRmNWJiIiwiZXhwIjoxNjk3MDU5NjgwfQ.AOnfVjP98oP5yoGiDGpf5qUHVda_NE5_aPxkTMezNcy0CiSaRFajpHhfZdpYS6w8y8gCP776d6qZ2mYKwu85OQOxEb6gfrn8v7Cf1I_XPfhB9CCtwjmJkOUMZRaq_BaIvq6FpE6Qr2tg0dlvVVt4DhS-51zSM67liC_D1uT0UYEkgn-X_wJNi8L8Sl7diNf2UFHStqpbYhM_1s_yEuImrvz93kFnjBcgbAqOvo11LyCXezdS9LD1o9vuIwIe18GrNeIBnXxuuEY_ZsAmdWREFiP_A_-YCWPy0Zfk8qXsLYwlpStQjXRlP7-OcTfrdS5Zy-pXtn8tt54F2x3eHbyXJg%2Fthumbnails%2Fthumbnail.jpg%3Ftime%3D10.0s"  aria-label="%00empty%00"  poster="https://videodelivery.net/eyJraWQiOiI3YjgzNTg3NDZlNWJmNDM0MjY5YzEwZTYwMDg0ZjViYiIsImFsZyI6IlJTMjU2In0.eyJzdWIiOiJjMDAwZGJlY2Y5ZWVjYmI3NjQyY2NhOTExMmNmMGU3ZCIsImtpZCI6IjdiODM1ODc0NmU1YmY0MzQyNjljMTBlNjAwODRmNWJiIiwiZXhwIjoxNjk3MDU5NjgwfQ.AOnfVjP98oP5yoGiDGpf5qUHVda_NE5_aPxkTMezNcy0CiSaRFajpHhfZdpYS6w8y8gCP776d6qZ2mYKwu85OQOxEb6gfrn8v7Cf1I_XPfhB9CCtwjmJkOUMZRaq_BaIvq6FpE6Qr2tg0dlvVVt4DhS-51zSM67liC_D1uT0UYEkgn-X_wJNi8L8Sl7diNf2UFHStqpbYhM_1s_yEuImrvz93kFnjBcgbAqOvo11LyCXezdS9LD1o9vuIwIe18GrNeIBnXxuuEY_ZsAmdWREFiP_A_-YCWPy0Zfk8qXsLYwlpStQjXRlP7-OcTfrdS5Zy-pXtn8tt54F2x3eHbyXJg/thumbnails/thumbnail.jpg?time=10.0s"  class="cloudflare-stream-player" id="video_stream_uuid%3A97f13d38-e64e-4415-b792-06e07125a043" height="374px" width="100%" allow="accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;" loading="lazy" allowfullscreen="true" ></iframe>
                            </p>
                            <div>Nittany AI Challenge Proposal Video</div>
                            <p>
                                <iframe height="374" width="100%" src="https://www.youtube.com/embed/KwiFrmnKLIk"></iframe>
                            </p>
                            <!-- <img src="assets/img/wavg-dist-dnn.png" style="height: 225px" /> -->
                        </div>
                        <!-- <div class="flex-shrink-0"><span class="text-primary">August 2015 - December 2019</span></div> -->
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0"><a href="https://news.engr.psu.edu/2021/nittany-ai-challenge-results.aspx">InsectEye</a></h3>
                            <div class="subheading mb-3">Awarded in <a href="https://nittanyai.psu.edu/alliance-programs/nittany-ai-challenge/results/2021-results/">2021 Nittany AI Challenge</a></div>
                            Developed an AI–based, nonlethal insect trap and identification system to assist entomologists in understanding insect biodiversity. Applied motion detection algorithm to capture insects in the trap and used Yolov3 network to classify them.<br>
                            <div>Nittany AI Challenge Proposal Video</div>
                            <p>
                                <iframe height="374" width="100%" src="https://www.youtube.com/embed/FcT93dHjOAU"></iframe>
                            </p>
                        </div>
                        <!-- <div class="flex-shrink-0"><span class="text-primary">March 2008 - February 2010</span></div> -->
                    </div>
                </div>
            </section>
            <!-- Skills-->
            <section class="resume-section" id="skills">
                <div class="resume-section-content">
                    <h2 class="mb-5">Skills</h2>
                    <div class="subheading mb-3">Languages</div>
                    <ul class="list-inline dev-icons">
                        <li class="list-inline-item">
                            <a href="https://docs.python.org/3/"><i class="iconify-inline" data-icon="vscode-icons:file-type-python"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://en.cppreference.com/w/c"><i class="iconify-inline" data-icon="teenyicons:c-solid"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://en.cppreference.com/w/cpp"><i class="iconify-inline" data-icon="teenyicons:cplusplus-solid"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://www.gnu.org/software/bash/"><i class="iconify-inline" data-icon="codicon:terminal-bash"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://www.latex-project.org/"><i class="iconify-inline" data-icon="vscode-icons:file-type-light-tex"></i></a>
                        </li>
                    </ul>
                    <div class="subheading mb-3">ML/DL Frameworks</div>
                    <ul class="list-inline dev-icons">
                        <li class="list-inline-item">
                            <a href="https://pytorch.org/docs/stable/index.html"><i class="iconify-inline" data-icon="logos:pytorch-icon"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://www.tensorflow.org/"><i class="iconify-inline" data-icon="logos:tensorflow"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://numpy.org/"><i class="iconify-inline" data-icon="logos:numpy"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://huggingface.co/docs"><i class="iconify-inline" data-icon="fluent-emoji-flat:hugging-face"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://spacy.io/api"><i class="iconify-inline" data-icon="simple-icons:spacy"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://onnx.ai/onnx/api/"><i class="iconify-inline" data-icon="simple-icons:onnx"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://github.com/NVIDIA/TensorRT"><i class="iconify-inline" data-icon="logos:nvidia"></i></a>
                        </li>
                    </ul>
                    <div class="subheading mb-3">Cloud Frameworks & Tools</div>
                    <ul class="list-inline dev-icons">
                        <li class="list-inline-item">
                            <a href="https://docs.aws.amazon.com/"><i class="iconify-inline" data-icon="logos:aws"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://docs.ray.io/en/latest/"><i class="iconify-inline" data-icon="simple-icons:ray"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://docs.docker.com/"><i class="iconify-inline" data-icon="logos:docker"></i></a>
                        </li>
                        <li class="list-inline-item">
                            <a href="https://git-scm.com/"><i class="iconify-inline" data-icon="logos:git"></i></a>
                        </li>
                    </ul>
                </div>
            </section>
            <hr class="m-0" />
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
